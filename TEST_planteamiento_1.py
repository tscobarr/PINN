import tensorflow as tf  # LibrerÃ­a para aprendizaje profundo
import numpy as np  # LibrerÃ­a para manipulaciÃ³n de matrices y cÃ¡lculos numÃ©ricos
import matplotlib.pyplot as plt  # LibrerÃ­a para visualizaciÃ³n de grÃ¡ficos
from matplotlib import rcParams  # ConfiguraciÃ³n de grÃ¡ficos
import os  # Manejo de archivos y directorios
import pandas as pd  # Manejo de datos en formato tabular
os.environ["KERAS_BACKEND"] = "tensorflow"  # Define TensorFlow como backend de Keras
import keras_core as keras  # LibrerÃ­a de redes neuronales basada en TensorFlow
import time  # Para medir tiempos de ejecuciÃ³n
import gc  # Para gestiÃ³n de la memoria (recolecciÃ³n de basura)
import psutil  # Para medir uso de CPU durante la ejecuciÃ³n de experimentos

# ConfiguraciÃ³n de reproducibilidad
keras.utils.set_random_seed(1234)  # Fija una semilla para asegurar resultados reproducibles
dtype = 'float32'  # Establece la precisiÃ³n de los cÃ¡lculos
keras.backend.set_floatx(dtype)  # Aplica el tipo de dato definido

# DefiniciÃ³n de parÃ¡metros globales
alpha = 1  # ParÃ¡metro utilizado en las ecuaciones diferenciales
limInf = 0  # LÃ­mite inferior del dominio de la soluciÃ³n
limSup = np.pi  # LÃ­mite superior del dominio de la soluciÃ³n
iterations = 1500

def makeModel1(neurons, nLayers, activation):
    xVals = keras.layers.Input(shape=(1,), name='x_input', dtype=dtype)
    l1 = keras.layers.Dense(neurons, activation=activation, dtype=dtype)(xVals)
    for l in range(nLayers - 2):
        l1 = keras.layers.Dense(neurons, activation=activation, dtype=dtype)(l1)
    output = keras.layers.Dense(1, activation=activation, dtype=dtype)(l1)
    uModel = keras.Model(inputs=xVals, outputs=output, name='u_model')
    return uModel

class Loss1(keras.layers.Layer):
    def __init__(self, uModel, nPts, f, lambda0=1, lambda1=1, lambda2=1, limInf=0, limSup=np.pi, **kwargs):
        super(Loss1, self).__init__()
        self.uModel = uModel
        self.nPts = nPts
        self.f = f
        self.lambda0 = lambda0
        self.lambda1 = lambda1
        self.lambda2 = lambda2
        self.limInf = limInf
        self.limSup = limSup

    def call(self, inputs):
        x = tf.random.uniform([self.nPts], self.limInf, self.limSup, dtype=dtype)
        with tf.GradientTape(persistent=True) as t1:
            t1.watch(x)
            with tf.GradientTape(persistent=True) as t2:
                t2.watch(x)
                u = self.uModel(x, training=True)
            dux = t2.gradient(u, x)
        duxx = t1.gradient(dux, x)
        errorPDE = self.lambda0 * keras.ops.mean((-duxx + alpha * u - self.f(x)) ** 2)
        bc = self.lambda1 * self.uModel(np.array([self.limInf])) ** 2 + self.lambda2 * self.uModel(np.array([self.limSup])) ** 2
        return errorPDE + bc

class RelativeErrorCallback(tf.keras.callbacks.Callback):
    def __init__(self, uModel, exactU, nPts):
        super().__init__()
        self.uModel = uModel
        self.exactU = exactU
        self.nPts = nPts

    def on_epoch_end(self, epoch, logs=None):
        Sval = tf.experimental.numpy.linspace(0., np.pi, num=self.nPts*10, dtype=dtype)
        with tf.GradientTape(persistent=True) as t1:
            t1.watch(Sval)
            ueval_val = self.uModel(Sval)
            u_x_val = t1.gradient(ueval_val, Sval)
            u_e = self.exactU(Sval)
            ue_x = t1.gradient(u_e, Sval)
        del t1
        errorH01 = tf.reduce_mean((ue_x - u_x_val)**2)
        norm_exact = tf.reduce_mean(ue_x**2)
        relative_error = errorH01 / norm_exact
        logs['relative_error'] = relative_error

def makeLossModel1(uModel, nPts, f, lambda0=1, lambda1=1, lambda2=1, limInf=0, limSup=np.pi):
    xVals = keras.layers.Input(shape=(1,), name='x_input', dtype=dtype)
    loss_output = Loss1(uModel, nPts, f, lambda0, lambda1, lambda2, limInf, limSup)(xVals)
    lossModel = keras.Model(inputs=xVals, outputs=loss_output)
    return lossModel

def trickyLoss(yPred, yTrue):
    return yTrue

def crear_estructura_directorios(base_path="experimentos/PLANTEAMIENTO 1"):
    """
    Crea la estructura de directorios necesarios para almacenar los resultados de los experimentos.
    
    ParÃ¡metros:
    - base_path (str): Ruta base donde se almacenarÃ¡n los resultados.
    
    Retorna:
    - base_path (str): Ruta base de los experimentos.
    - graficas_path (str): Ruta donde se guardarÃ¡n las grÃ¡ficas generadas.
    - mejores_path (str): Ruta especÃ­fica para almacenar los mejores resultados.
    - peores_path (str): Ruta especÃ­fica para almacenar los peores resultados.
    """
    graficas_path = os.path.join(base_path, "graficas")

    
    print("âœ” Directorios creados correctamente.")
    return base_path, graficas_path

def inicializar_excel(file_path="experimentos/PLANTEAMIENTO 1/resultados.xlsx"):
    """
    Crea un archivo Excel con la estructura inicial si no existe. 
    El archivo contendrÃ¡ tres hojas llamadas "Lote 1", "Lote 2" y "Lote 3",
    donde se almacenarÃ¡n los resultados de los experimentos.

    ParÃ¡metros:
    - file_path (str): Ruta del archivo Excel donde se guardarÃ¡n los datos.

    Retorna:
    - file_path (str): Ruta del archivo Excel.
    """
    if not os.path.exists(file_path):
        writer = pd.ExcelWriter(file_path, engine='xlsxwriter')
        for i in range(1, 4):
            # Definir las columnas del archivo Excel
            df = pd.DataFrame(columns=[
                "Experimento", "neurons", "nLayers", "nPts", 
                "lambda0", "lambda1", "lambda2", "ERROR RELATIVO", "COSTO COMPUTACIONAL"
            ])
            df.to_excel(writer, sheet_name=f"Lote {i}", index=False)
        writer.close()
        print("âœ” Archivo Excel inicializado.")
    else:
        print("âœ” Archivo Excel ya existe.")
    
    return file_path

# FunciÃ³n para obtener los hiperparÃ¡metros por defecto
def hiperparametros_por_defecto():
    """
    Devuelve un diccionario con valores predeterminados para los hiperparÃ¡metros de la PINN.

    Retorna:
    - dict: Diccionario con los hiperparÃ¡metros iniciales.
    """
    return {
        "neurons": 10,  # NÃºmero de neuronas por capa
        "nLayers": 5,  # NÃºmero de capas ocultas
        "nPts": 2000,  # NÃºmero de puntos en el dominio
        "lambda0": 5,  # Peso del error de la ecuaciÃ³n diferencial
        "lambda1": 7,  # Peso del error en el contorno inferior
        "lambda2": 7   # Peso del error en el contorno superior
    }

# FunciÃ³n para generar hiperparÃ¡metros aleatorios dentro de ciertos rangos
def randomizar_hiperparametros():
    """
    Genera un conjunto aleatorio de hiperparÃ¡metros dentro de ciertos rangos predefinidos.

    Retorna:
    - dict: Diccionario con hiperparÃ¡metros aleatorios.
    """
    return {
        "neurons": np.random.randint(4, 11),  # Neuronas entre 4 y 10
        "nLayers": np.random.randint(4, 6),  # Capas entre 4 y 5
        "nPts": np.random.randint(500, 3001),  # Puntos entre 500 y 3000
        "lambda0": np.random.randint(1, 11),  # Peso entre 1 y 10
        "lambda1": np.random.randint(4, 11),  # Peso entre 4 y 10
        "lambda2": np.random.randint(4, 11)   # Peso entre 4 y 10
    }

# FunciÃ³n para definir la pÃ©rdida y entrenamiento
def train_PINN(hiperparametros, funcion_referencia, funcion_exacta):
    """
    Entrena la PINN con los hiperparÃ¡metros dados y la funciÃ³n de referencia seleccionada.

    TambiÃ©n mide el error relativo y el costo computacional en tÃ©rminos de uso de CPU.

    ParÃ¡metros:
    - hiperparametros (dict): Diccionario con la configuraciÃ³n de la red (neurons, nLayers, etc.).
    - funcion_referencia (funciÃ³n): FunciÃ³n f(x) en la ecuaciÃ³n diferencial que la PINN debe aprender.
    - funcion_exacta (funciÃ³n): SoluciÃ³n exacta esperada para evaluar el error relativo.

    Retorna:
    - error_relativo (float): Error relativo entre la soluciÃ³n de la PINN y la soluciÃ³n exacta.
    - costo_computacional (float): Uso de CPU en porcentaje durante el entrenamiento.
    - history (tf.keras.callbacks.History): Historial del entrenamiento.
    - uModel (keras.Model): Modelo entrenado de la PINN.
    - xList (array): Puntos en el dominio donde se evaluÃ³ la soluciÃ³n.
    """

    # ðŸ“Œ Medir uso de CPU antes del entrenamiento
    cpu_usage_before = psutil.cpu_percent(interval=None)

    # ðŸ”¹ ConstrucciÃ³n del modelo de red neuronal PINN
    uModel = makeModel1(
        neurons=hiperparametros["neurons"],
        nLayers=hiperparametros["nLayers"],
        activation='tanh'
    )

    # # ðŸ“Œ Calcular valores exactos en los bordes (x = 0 y x = Ï€)
    # A = funcion_exacta(0)  # ðŸ“Œ Valor exacto en x = 0
    # B = funcion_exacta(np.pi)  # ðŸ“Œ Valor exacto en x = Ï€

    # ðŸ”¹ Definir el modelo de pÃ©rdida basado en la ecuaciÃ³n diferencial
    lossModel = makeLossModel1(
        uModel,
        hiperparametros["nPts"],
        funcion_referencia,  # ðŸ“Œ FunciÃ³n f(x)
        hiperparametros["lambda0"],
        hiperparametros["lambda1"],
        hiperparametros["lambda2"],
        limInf, limSup,
        # A, B  # ðŸ“Œ Se pasan los valores exactos en los extremos
    )

    # ðŸ“Œ Configurar el optimizador y la funciÃ³n de pÃ©rdida (trickyLoss)
    optimizer = keras.optimizers.Adam(learning_rate=1e-3)
    lossModel.compile(optimizer=optimizer, loss=trickyLoss)

    relative_error_callback = RelativeErrorCallback(uModel, funcion_referencia, hiperparametros["nPts"])
    # ðŸ“Œ Entrenamiento de la PINN
    history = lossModel.fit(
        np.array([1.]), np.array([1.]), epochs=iterations, verbose=0, callbacks=[relative_error_callback]
    )

    # ðŸ”¹ Generar puntos en el dominio para evaluar la soluciÃ³n entrenada
    xList = np.array([np.pi / 1000 * i for i in range(1000)])

    # ðŸ”¹ Evaluar la soluciÃ³n aproximada y compararla con la soluciÃ³n exacta
    error_relativo = history.history['relative_error'][-1].numpy()

    # ðŸ“Œ Medir uso de CPU despuÃ©s del entrenamiento
    cpu_usage_after = psutil.cpu_percent(interval=None)
    cpu_cost = cpu_usage_after - cpu_usage_before  # ðŸ“Œ CÃ¡lculo del costo computacional

    # ðŸ”¹ Liberar memoria
    keras.backend.clear_session()
    gc.collect()

    return error_relativo, cpu_cost, history, uModel, xList  # ðŸ“Œ Retornar mÃ©tricas clave y el modelo entrenado

def ejecutar_experimentos(func, n_experimentos=45):  
    """
    Ejecuta mÃºltiples experimentos de entrenamiento de la PINN con diferentes hiperparÃ¡metros.

    Se generan varios lotes de experimentos con diferentes configuraciones de hiperparÃ¡metros 
    para evaluar la estabilidad y precisiÃ³n del modelo en distintas condiciones.

    ParÃ¡metros:
    - func (lista de tuplas): Lista de funciones de referencia y soluciones exactas esperadas.
      Cada elemento es una tupla (funciÃ³n_f, funciÃ³n_u_exacta).
    - n_experimentos (int, opcional): NÃºmero total de experimentos a ejecutar. Por defecto, 45.

    Retorna:
    - resultados (lista): Lista de resultados de los experimentos, donde cada elemento contiene:
      [ID, neurons, nLayers, nPts, lambda0, lambda1, lambda2, error_relativo, costo_computacional, 
      modelo entrenado, historial, soluciÃ³n exacta, xList].
    """

    # ðŸ“Œ Determinar la cantidad de lotes basada en el nÃºmero de experimentos
    num_lotes = min(len(func), n_experimentos)  
    lote_size = n_experimentos // num_lotes  # ðŸ“Œ NÃºmero de experimentos por lote

    # ðŸ“Œ Generar hiperparÃ¡metros aleatorios para cada lote (excepto el primero, que es por defecto)
    hiperparametros_aleatorios = [randomizar_hiperparametros() for _ in range(lote_size - 1)]  

    # ðŸ“Œ Lista para almacenar resultados
    resultados = []

    for i in range(num_lotes):
        # ðŸ”¹ Seleccionar la funciÃ³n de referencia y la soluciÃ³n exacta
        f_rhs, exactU = func[i]  
        print(f"\nðŸ”¹ Ejecutando Lote {i+1}...\n")

        for j in range(lote_size):
            experimento_id = i * lote_size + j + 1
            print(f"   â–¶ Ejecutando experimento {experimento_id}...")

            # ðŸ”¹ Para el primer experimento de cada lote, usar hiperparÃ¡metros por defecto
            if j == 0:
                hiperparametros = hiperparametros_por_defecto()
            else:
                hiperparametros = hiperparametros_aleatorios[j - 1]

            # ðŸ”¹ Entrenar la PINN con la configuraciÃ³n actual
            error_relativo, costo_computacional, history, uModel, xList = train_PINN(hiperparametros, f_rhs, exactU)

            # Imprimir resultados del experimento
            print(f"      ðŸ”¹ Completado - Error relativo: {error_relativo:.5f}, Uso CPU: {costo_computacional:.2f}%")

            # ðŸ“Œ Guardar los resultados del experimento
            resultados.append([
                experimento_id, 
                hiperparametros["neurons"], 
                hiperparametros["nLayers"], 
                hiperparametros["nPts"], 
                hiperparametros["lambda0"], 
                hiperparametros["lambda1"], 
                hiperparametros["lambda2"], 
                error_relativo, 
                costo_computacional,  
                uModel,   
                history,  
                exactU,   
                xList     
            ])

    return resultados

# ðŸ”¹ Definimos las funciones de referencia y sus soluciones exactas en un diccionario
funciones_experimentos = [
    {
        'fRhs': lambda x: (alpha + 4) * keras.ops.sin(2 * x),
        'exactU': lambda x: keras.ops.sin(2 * x),
        'title': 'sin(2x)'
    },
    {
        'fRhs': lambda x: 17/4 * keras.ops.sin(2 * x) * keras.ops.cos(x / 2) + 2 * keras.ops.sin(x / 2) * keras.ops.cos(2 * x) + alpha * keras.ops.sin(2 * x) * keras.ops.cos(x / 2),
        'exactU': lambda x: keras.ops.sin(2 * x) * keras.ops.cos(x / 2),
        'title': 'sin(2x) * cos(x/2)'
    },
    {
        'fRhs': lambda x: - 2 * (6 * x**2 - 6 * np.pi * x + np.pi**2) + alpha * (x**2 * (x - np.pi)**2),
        'exactU': lambda x: x**2 * (x - np.pi)**2,
        'title': 'x^2 * (x - pi)^2'
    }
]

# ðŸ”¹ Convertir el diccionario en una lista de tuplas
func = [(exp['fRhs'], exp['exactU']) for exp in funciones_experimentos]

def guardar_resultados_excel(resultados, file_path="experimentos/PLANTEAMIENTO 1/resultados.xlsx"):
    """
    Guarda los resultados de los experimentos en un archivo Excel, separando por lote.

    Cada hoja del archivo representa un conjunto de experimentos con la misma funciÃ³n de referencia.

    ParÃ¡metros:
    - resultados (lista): Lista de resultados obtenidos de `ejecutar_experimentos`.
    - file_path (str, opcional): Ruta del archivo Excel donde se guardarÃ¡n los datos.

    Retorna:
    - None
    """
    from openpyxl import load_workbook

    # ðŸ“Œ Cargar o crear un archivo Excel
    if os.path.exists(file_path):
        writer = pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='overlay')
    else:
        writer = pd.ExcelWriter(file_path, engine='xlsxwriter')

    # ðŸ“Œ Recorrer cada experimento y guardarlo en su respectiva hoja
    for i, experimento in enumerate(funciones_experimentos):
        lote_resultados = [
            [r[j] for j in range(9)] for r in resultados if (r[0] - 1) // (len(resultados) // len(funciones_experimentos)) == i
        ]

        df = pd.DataFrame(
            lote_resultados,
            columns=["Experimento", "neurons", "nLayers", "nPts", 
                     "lambda0", "lambda1", "lambda2", "ERROR RELATIVO", "COSTO COMPUTACIONAL (CPU %)"]
        )

        # Reemplazar caracteres invÃ¡lidos en el nombre de la hoja
        sheet_name = experimento['title'].replace('*', '').replace('/', '').replace('\\', '').replace('[', '').replace(']', '').replace(':', '').replace('?', '')

        df.to_excel(writer, sheet_name=sheet_name, index=False)

    # ðŸ“Œ Guardar los cambios
    writer.close()
    print(f"âœ” Resultados guardados en {file_path} con las funciones correctamente organizadas.")

def plot_results(uModel, history, exactU, xList, exp_folder):
    """
    Genera y guarda las grÃ¡ficas de un experimento, asegurando que se use la funciÃ³n exacta correcta.
    """
    rcParams['font.family'] = 'serif'
    rcParams['font.size'] = 14
    rcParams['legend.fontsize'] = 12
    rcParams['mathtext.fontset'] = 'cm'
    rcParams['axes.labelsize'] = 14

    # ComparaciÃ³n de la soluciÃ³n exacta y la aproximada
    fig, ax = plt.subplots()
    plt.plot(xList, uModel(xList), color='b', label="u_approx")
    plt.plot(xList, exactU(xList), color='m', label="u_exact")  # âœ… Se asegura que usa la funciÃ³n exacta correcta
    plt.legend()
    ax.grid(which='both', linestyle=':')
    plt.tight_layout()
    plt.savefig(os.path.join(exp_folder, "comparacion_u.png"), dpi=300)
    plt.close()

    # EvoluciÃ³n de la pÃ©rdida y error relativo
    fig, ax1 = plt.subplots()
    ax1.plot(history.history['loss'], color='g', label="Loss")
    ax1.set_xscale('log')
    ax1.set_yscale('log')
    ax1.set_xlabel("Epoch")
    ax1.set_ylabel("Loss", color='g')

    ax2 = ax1.twinx()
    ax2.plot(history.history['loss'], color='b', label="Relative Error")  # ðŸ“Œ Se debe reemplazar por la mÃ©trica correcta
    ax2.set_ylabel("Relative Error", color='b')

    ax1.grid(which='both', linestyle=':')
    plt.tight_layout()
    plt.savefig(os.path.join(exp_folder, "error_vs_loss.png"), dpi=300)
    plt.close()

    # Error relativo a lo largo de las Ã©pocas
    fig, ax = plt.subplots()
    plt.plot(history.history['loss'], color='b', label="Relative Error")  # ðŸ“Œ Se debe ajustar con la mÃ©trica real
    ax.set_xscale('log')
    plt.legend()
    ax.grid(which='both', linestyle=':')
    plt.tight_layout()
    plt.savefig(os.path.join(exp_folder, "error_relativo.png"), dpi=300)
    plt.close()

def seleccionar_experimentos(resultados):
    """
    Selecciona los experimentos que se van a graficar y los organiza en una lista.

    ParÃ¡metros:
    - resultados (lista): Lista de resultados obtenidos en `ejecutar_experimentos`.

    Retorna:
    - todos_experimentos (lista): Lista de experimentos seleccionados para graficar.
    """

    # ðŸ“Œ Determinar la cantidad de lotes segÃºn los experimentos disponibles
    num_lotes = min(len(func), len(resultados))  
    lote_size = max(1, len(resultados) // num_lotes)  

    # ðŸ“Œ Lista para almacenar los experimentos seleccionados
    todos_experimentos = []

    for i in range(num_lotes):
        # ðŸ”¹ Seleccionar experimentos de este lote
        lote_resultados = [r for r in resultados if (r[0] - 1) // lote_size == i]
        todos_experimentos.extend(lote_resultados)

    print("âœ” Experimentos listos para generar grÃ¡ficas.")
    return todos_experimentos

def generar_graficas(experimentos, resultados, graficas_path):
    """
    Genera y guarda las grÃ¡ficas de los experimentos en una carpeta especÃ­fica.

    Cada experimento tendrÃ¡ su propia carpeta donde se guardarÃ¡n:
    - La comparaciÃ³n entre la soluciÃ³n exacta y la aproximada.
    - La evoluciÃ³n de la pÃ©rdida durante el entrenamiento.
    - La evoluciÃ³n del error relativo.
    - La comparaciÃ³n entre la pÃ©rdida y el error relativo.

    ParÃ¡metros:
    - experimentos (lista): Lista de experimentos seleccionados para graficar.
    - resultados (lista): Lista de resultados obtenidos en `ejecutar_experimentos`.
    - graficas_path (str): Ruta donde se almacenarÃ¡n las grÃ¡ficas.

    Retorna:
    - None
    """

    for exp in experimentos:
        exp_id = exp[0]  # ID del experimento
        exp_folder = os.path.join(graficas_path, f"Experimento_{exp_id}")
        os.makedirs(exp_folder, exist_ok=True)  # ðŸ“Œ Crear carpeta del experimento si no existe

        # ðŸ”¹ Extraer datos del experimento correspondiente
        uModel, history, exactU, xList = resultados[exp_id - 1][9:]

        # ðŸ“Œ Generar las grÃ¡ficas
        plot_results(uModel, history, exactU, xList, exp_folder)

    print(f"âœ” Todas las grÃ¡ficas generadas en {graficas_path}.")

# ðŸ”¹ Paso 1: ConfiguraciÃ³n inicial (Crear directorios y archivo Excel)
print("ðŸ“‚ Configurando estructura de almacenamiento...")
base_path, graficas_path = crear_estructura_directorios()
excel_file = inicializar_excel()

# ðŸ”¹ Paso 2: Ejecutar experimentos
print("ðŸš€ Ejecutando experimentos...")
resultados_experimentos = ejecutar_experimentos(func)

# ðŸ”¹ Paso 3: Seleccionar los experimentos para graficar
print("ðŸ“Š Seleccionando experimentos para generaciÃ³n de grÃ¡ficas...")
experimentos_seleccionados = seleccionar_experimentos(resultados_experimentos)

# ðŸ”¹ Paso 4: Generar todas las grÃ¡ficas
print("ðŸ“ˆ Generando grÃ¡ficas...")
generar_graficas(experimentos_seleccionados, resultados_experimentos, graficas_path)

# ðŸ”¹ Paso 5: Guardar los resultados en Excel
print("ðŸ’¾ Guardando resultados en archivo Excel...")
guardar_resultados_excel(resultados_experimentos)

print("âœ… Proceso finalizado exitosamente.")