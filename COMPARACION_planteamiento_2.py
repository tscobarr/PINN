import tensorflow as tf  # LibrerÃ­a para aprendizaje profundo
import numpy as np  # LibrerÃ­a para manipulaciÃ³n de matrices y cÃ¡lculos numÃ©ricos
import matplotlib.pyplot as plt  # LibrerÃ­a para visualizaciÃ³n de grÃ¡ficos
from matplotlib import rcParams  # ConfiguraciÃ³n de grÃ¡ficos
import os  # Manejo de archivos y directorios
import pandas as pd  # Manejo de datos en formato tabular
os.environ["KERAS_BACKEND"] = "tensorflow"  # Define TensorFlow como backend de Keras
import keras_core as keras  # LibrerÃ­a de redes neuronales basada en TensorFlow
import gc  # Para gestiÃ³n de la memoria (recolecciÃ³n de basura)
import psutil  # Para medir uso de CPU durante la ejecuciÃ³n de experimentos
import time

# ConfiguraciÃ³n de reproducibilidad
keras.utils.set_random_seed(1234)  # Fija una semilla para asegurar resultados reproducibles
dtype = 'float32'  # Establece la precisiÃ³n de los cÃ¡lculos
keras.backend.set_floatx(dtype)  # Aplica el tipo de dato definido
# DefiniciÃ³n de parÃ¡metros globales

alpha = 1  # ParÃ¡metro utilizado en las ecuaciones diferenciales
limInf = 0  # LÃ­mite inferior del dominio de la soluciÃ³n
limSup = np.pi  # LÃ­mite superior del dominio de la soluciÃ³n
iterations = 5 # epocas por experimento

def makeModel2(neurons, nLayers, activation, limInf=0, limSup=np.pi):
    """
    Crea el modelo de la PINN con condiciones de frontera impuestas.
    
    ParÃ¡metros:
    - neurons (int): NÃºmero de neuronas por capa.
    - nLayers (int): NÃºmero de capas ocultas.
    - activation (str): FunciÃ³n de activaciÃ³n.
    - limInf (float): LÃ­mite inferior del dominio.
    - limSup (float): LÃ­mite superior del dominio.

    Retorna:
    - uModel (keras.Model): Modelo de la PINN con condiciones de frontera incorporadas.
    """
    xVals = keras.layers.Input(shape=(1,), name='x_input', dtype=dtype)
    l1 = keras.layers.Dense(neurons, activation=activation, dtype=dtype)(xVals)
    
    for _ in range(nLayers - 2):
        l1 = keras.layers.Dense(neurons, activation=activation, dtype=dtype)(l1)
    
    output = keras.layers.Dense(1, activation=activation, dtype=dtype)(l1)
    
    # ðŸ”¹ Impone las condiciones de frontera directamente en la salida
    boundaryC = keras.layers.Lambda(lambda x: (x - limInf) * (x - limSup))(xVals)
    output = keras.layers.Multiply()([output, boundaryC])
    
    uModel = keras.Model(inputs=xVals, outputs=output, name='u_model')
    return uModel

class Loss2(keras.layers.Layer):
    """
    Capa personalizada para calcular la pÃ©rdida en el Planteamiento 2.
    No penaliza las condiciones de frontera, ya que estÃ¡n impuestas en la arquitectura.
    """

    def __init__(self, uModel, nPts, f, limInf=0, limSup=np.pi, **kwargs):
        super(Loss2, self).__init__()
        self.uModel = uModel
        self.nPts = nPts
        self.f = f
        self.limInf = limInf
        self.limSup = limSup

    def call(self, inputs):
        x = tf.random.uniform([self.nPts], dtype=dtype, minval=self.limInf, maxval=self.limSup)
        
        with tf.GradientTape(persistent=True) as t1:
            t1.watch(x)
            with tf.GradientTape(persistent=True) as t2:
                t2.watch(x)
                u = self.uModel(x, training=True)
            dux = t2.gradient(u, x)
        duxx = t1.gradient(dux, x)

        errorPDE = keras.ops.mean((-duxx + alpha * u - self.f(x)) ** 2)
        return errorPDE

def makeLossModel2(uModel, nPts, f, limInf=0, limSup=np.pi):
    """
    Crea el modelo de pÃ©rdida basado en la ecuaciÃ³n diferencial para el Planteamiento 2.

    ParÃ¡metros:
    - uModel (keras.Model): Modelo de la PINN.
    - nPts (int): NÃºmero de puntos de muestreo en el dominio.
    - f (funciÃ³n): FunciÃ³n de referencia f(x).
    - limInf (float): LÃ­mite inferior del dominio.
    - limSup (float): LÃ­mite superior del dominio.

    Retorna:
    - lossModel (keras.Model): Modelo de pÃ©rdida para la PINN.
    """

    # ðŸ”¹ Entrada del modelo (valores de x en el dominio)
    xVals = keras.layers.Input(shape=(1,), name='x_input', dtype=dtype)

    # ðŸ”¹ Capa de pÃ©rdida personalizada
    loss_output = Loss2(uModel, nPts, f, limInf, limSup)(xVals)

    # ðŸ”¹ CreaciÃ³n del modelo de pÃ©rdida
    lossModel = keras.Model(inputs=xVals, outputs=loss_output)

    return lossModel

class RelativeErrorCallback(tf.keras.callbacks.Callback):
    """
    Callback personalizado para calcular el error relativo en norma HÂ¹ al final de cada Ã©poca.
    """

    def __init__(self, uModel, exactU, nPts):
        super().__init__()
        self.uModel = uModel
        self.exactU = exactU
        self.nPts = nPts

    def on_epoch_end(self, epoch, logs=None):
        Sval = tf.experimental.numpy.linspace(0., np.pi, num=self.nPts * 10, dtype=dtype)

        with tf.GradientTape(persistent=True) as t1:
            t1.watch(Sval)
            ueval_val = self.uModel(Sval)  # SoluciÃ³n aproximada de la PINN
            u_x_val = t1.gradient(ueval_val, Sval)  # Derivada de la soluciÃ³n aproximada
            u_e = self.exactU(Sval)  # SoluciÃ³n exacta
            ue_x = t1.gradient(u_e, Sval)  # Derivada de la soluciÃ³n exacta
        del t1  # Liberar memoria

        errorH01 = tf.reduce_mean((ue_x - u_x_val) ** 2)
        norm_exact = tf.reduce_mean(ue_x ** 2)
        relative_error = errorH01 / norm_exact

        logs['relative_error'] = relative_error

def medir_costo_computacional(funcion_entrenamiento, *args, **kwargs):
    """
    Esta funciÃ³n mide el porcentaje de uso de CPU y el tiempo total transcurrido durante la ejecuciÃ³n de una funciÃ³n especÃ­fica. 
    Su propÃ³sito es evaluar el costo computacional de un proceso en tÃ©rminos de utilizaciÃ³n del procesador.

    Para lograrlo, la funciÃ³n realiza las siguientes mediciones antes y despuÃ©s de la ejecuciÃ³n de la funciÃ³n objetivo:
    1. **Tiempo de CPU utilizado**: Representa el tiempo total que la CPU ha dedicado activamente a ejecutar la funciÃ³n, 
    sin contar periodos de inactividad o espera.
    2. **Tiempo real transcurrido**: Es el tiempo total que ha pasado desde el inicio hasta el final de la ejecuciÃ³n de la funciÃ³n.
    3. **NÃºmero de nÃºcleos lÃ³gicos del procesador**: Determina la capacidad total del sistema para distribuir la carga de trabajo.

    El cÃ¡lculo del uso de CPU se realiza dividiendo el tiempo de CPU utilizado entre el producto del tiempo real transcurrido 
    y el nÃºmero de nÃºcleos lÃ³gicos. Esto permite normalizar la mediciÃ³n para obtener un valor porcentual que refleja 
    quÃ© tanto del poder total del procesador fue utilizado durante la ejecuciÃ³n.

    ParÃ¡metros:
    - funcion_entrenamiento (funciÃ³n): La funciÃ³n que queremos medir.
    - *args: Argumentos posicionales de la funciÃ³n.
    - **kwargs: Argumentos con nombre de la funciÃ³n.

    Retorna:
    - cpu_percent (float): Porcentaje medio de CPU usado durante la ejecuciÃ³n.
    - elapsed_time (float): Tiempo total transcurrido en segundos.
    """

    process = psutil.Process(os.getpid())  # Obtener el proceso actual

    # ðŸ”¹ Medir el tiempo de CPU y tiempo real antes del entrenamiento
    cpu_times_before = process.cpu_times()
    time_before = time.time()

    # ðŸ”¹ Ejecutar la funciÃ³n de entrenamiento con sus argumentos
    funcion_entrenamiento(*args, **kwargs)

    # ðŸ”¹ Medir el tiempo de CPU y tiempo real despuÃ©s del entrenamiento
    cpu_times_after = process.cpu_times()
    time_after = time.time()

    # ðŸ”¹ Calcular tiempo total de CPU consumido
    cpu_time_used = (cpu_times_after.user + cpu_times_after.system) - (cpu_times_before.user + cpu_times_before.system)

    # ðŸ”¹ Calcular tiempo real transcurrido
    elapsed_time = time_after - time_before

    # ðŸ”¹ Calcular porcentaje de CPU usado
    num_cpus = psutil.cpu_count(logical=True)  # NÃºmero de nÃºcleos lÃ³gicos
    cpu_percent = (cpu_time_used / (elapsed_time * num_cpus)) * 100 if elapsed_time > 0 else 0

    return cpu_percent, elapsed_time

def train_PINN(hiperparametros, funcion_referencia, funcion_exacta):
    """
    Entrena la PINN con los hiperparÃ¡metros dados y la funciÃ³n de referencia seleccionada.

    ParÃ¡metros:
    - hiperparametros (dict): Diccionario con la configuraciÃ³n de la red (neurons, nLayers, etc.).
    - funcion_referencia (funciÃ³n): FunciÃ³n f(x) en la ecuaciÃ³n diferencial que la PINN debe aprender.
    - funcion_exacta (funciÃ³n): SoluciÃ³n exacta esperada para evaluar el error relativo.

    Retorna:
    - error_relativo (float): Error relativo entre la soluciÃ³n de la PINN y la soluciÃ³n exacta.
    - cpu_cost (float): Tiempo total de CPU consumido durante el entrenamiento.
    - history (tf.keras.callbacks.History): Historial del entrenamiento.
    - uModel (keras.Model): Modelo entrenado de la PINN.
    - xList (array): Puntos en el dominio donde se evaluÃ³ la soluciÃ³n.
    """

    # ðŸ”¹ ConstrucciÃ³n del modelo de red neuronal PINN
    uModel = makeModel2(
        neurons=hiperparametros["neurons"],
        nLayers=hiperparametros["nLayers"],
        activation='tanh',
        limInf=limInf,
        limSup=limSup
    )

    # ðŸ”¹ Definir el modelo de pÃ©rdida basado en la ecuaciÃ³n diferencial
    lossModel = makeLossModel2(
        uModel,
        hiperparametros["nPts"],
        funcion_referencia,
        limInf, limSup
    )

    # ðŸ”¹ Configurar el optimizador y la funciÃ³n de pÃ©rdida
    optimizer = keras.optimizers.Adam(learning_rate=1e-3)
    lossModel.compile(optimizer=optimizer, loss=trickyLoss)

    relative_error_callback = RelativeErrorCallback(uModel, funcion_exacta, hiperparametros["nPts"])

    # ðŸ”¹ Entrenamiento de la PINN
    history = lossModel.fit(
        np.array([1.]), np.array([1.]), epochs=iterations, verbose=0, callbacks=[relative_error_callback]
    )

    # ðŸ”¹ Evaluar la soluciÃ³n aproximada y compararla con la soluciÃ³n exacta
    error_relativo = history.history.get('relative_error', [np.nan])[-1]

    # ðŸ”¹ Medir el porcentaje de CPU utilizado durante el entrenamiento
    cpu_cost, _ = medir_costo_computacional(
        lossModel.fit, np.array([1.]), np.array([1.]), epochs=iterations, verbose=0, callbacks=[relative_error_callback]
    )

    # ðŸ”¹ Generar puntos en el dominio para evaluar la soluciÃ³n entrenada
    xList = np.linspace(limInf, limSup, 1000)

    # ðŸ”¹ Liberar memoria
    keras.backend.clear_session()
    gc.collect()

    return error_relativo, cpu_cost, history, uModel, xList

# FunciÃ³n para obtener los hiperparÃ¡metros por defecto
def hiperparametros_por_defecto_2():
    """
    Devuelve un diccionario con valores optimos para los hiperparÃ¡metros de la PINN que fueron determinados
    experimentalmente.

    Retorna:
    - dict: Diccionario con los hiperparÃ¡metros iniciales.
    """
    return {
        "neurons": 8,  # NÃºmero de neuronas por capa
        "nLayers": 5,  # NÃºmero de capas ocultas
        "nPts": 1608,  # NÃºmero de puntos en el dominio
    }

def ejecutar_entrenamientos(funciones_experimentos, n_experimentos=45):  
    """
    Ejecuta mÃºltiples entrenamientos de la PINN con los primeros hiperparÃ¡metros que fueron seleccionados como Ã³ptimos a partir de los experimentos.

    ParÃ¡metros:
    - funciones_experimentos (lista): Lista de funciones de referencia y soluciones exactas.
    - n_experimentos (int, opcional): NÃºmero total de experimentos a ejecutar.

    Retorna:
    - resultados (lista): Lista de resultados de los experimentos, donde cada elemento contiene:
      [ID, neurons, nLayers, nPts, error_relativo, costo_computacional, modelo entrenado, historial, soluciÃ³n exacta, xList].
    """

    # ðŸ“Œ HiperparÃ¡metros fijos dados por los experimentos del planteamiento 1
    hiperparametros= hiperparametros_por_defecto_2()

    num_lotes = min(len(funciones_experimentos), n_experimentos)  
    lote_size = n_experimentos // num_lotes  

    resultados = []

    for i in range(num_lotes):
        f_rhs, exactU = funciones_experimentos[i]  
        print(f"\nðŸ”¹ Ejecutando Lote {i+1}...\n")

        for j in range(lote_size):
            experimento_id = i * lote_size + j + 1
            print(f"   â–¶ Ejecutando experimento {experimento_id}...")

            error_relativo, cpu_cost, history, uModel, xList = train_PINN(hiperparametros, f_rhs, exactU)

            print(f"      ðŸ”¹ Completado - Error relativo: {error_relativo:.5f}, Uso CPU: {cpu_cost:.2f}%")

            resultados.append([
                experimento_id, 
                hiperparametros["neurons"], 
                hiperparametros["nLayers"], 
                hiperparametros["nPts"], 
                error_relativo, 
                cpu_cost,  
                uModel,   
                history,  
                exactU,   
                xList     
            ])

    return resultados

def trickyLoss(yPred, yTrue):
    """
    FunciÃ³n de pÃ©rdida ficticia utilizada en el entrenamiento de la PINN.

    Dado que la pÃ©rdida real es calculada por la capa `Loss1`, esta funciÃ³n 
    simplemente devuelve `yTrue` sin hacer ningÃºn cÃ¡lculo. 

    ParÃ¡metros:
    - yPred (tensor): PredicciÃ³n del modelo de pÃ©rdida (`lossModel`).
    - yTrue (tensor): Etiqueta objetivo (se ignora).

    Retorna:
    - yTrue (tensor): Se devuelve sin modificaciones.
    """
    return yTrue

# ðŸ”¹ Definimos las funciones de referencia y sus soluciones exactas en un diccionario
funciones_experimentos = [
    {
        'fRhs': lambda x: (alpha + 4) * keras.ops.sin(2 * x),
        'exactU': lambda x: keras.ops.sin(2 * x),
        'title': 'sin(2x)'
    },
    {
        'fRhs': lambda x: (17/4) * keras.ops.sin(2 * x) * keras.ops.cos(x / 2) + 
                          2 * keras.ops.sin(x / 2) * keras.ops.cos(2 * x) + 
                          alpha * keras.ops.sin(2 * x) * keras.ops.cos(x / 2),
        'exactU': lambda x: keras.ops.sin(2 * x) * keras.ops.cos(x / 2),
        'title': 'sin(2x) * cos(x/2)'
    },
    {
        'fRhs': lambda x: -2 * (6 * x**2 - 6 * np.pi * x + np.pi**2) + 
                          alpha * (x**2 * (x - np.pi)**2),
        'exactU': lambda x: x**2 * (x - np.pi)**2,
        'title': 'x^2 * (x - pi)^2'
    }
]
# ðŸ”¹ Convertir el diccionario en una lista de tuplas
func = [(exp['fRhs'], exp['exactU']) for exp in funciones_experimentos]

def crear_estructura_directorios(base_path="resultados/PLANTEAMIENTO_2"):
    """
    Crea la estructura de directorios para almacenar los resultados de los experimentos.

    ParÃ¡metros:
    - base_path (str): Ruta base donde se almacenarÃ¡n los resultados.

    Retorna:
    - base_path (str): Ruta base de los experimentos.
    - graficas_path (str): Ruta donde se guardarÃ¡n las grÃ¡ficas generadas.
    """
    os.makedirs(base_path, exist_ok=True)
    graficas_path = os.path.join(base_path, "graficas")
    os.makedirs(graficas_path, exist_ok=True)

    return base_path, graficas_path

def plot_results(uModel, history, exactU, xList, exp_folder):
    """
    Genera y guarda las grÃ¡ficas de un experimento, asegurando que se use la funciÃ³n exacta correcta.

    ParÃ¡metros:
    - uModel (keras.Model): Modelo entrenado de la PINN.
    - history (tf.keras.callbacks.History): Historial de entrenamiento.
    - exactU (funciÃ³n): FunciÃ³n de la soluciÃ³n exacta.
    - xList (array): Puntos en el dominio donde se evaluÃ³ la soluciÃ³n.
    - exp_folder (str): Ruta donde se guardarÃ¡n las grÃ¡ficas.

    Retorna:
    - None
    """
    rcParams['font.family'] = 'serif'
    rcParams['font.size'] = 14
    rcParams['legend.fontsize'] = 12
    rcParams['mathtext.fontset'] = 'cm'
    rcParams['axes.labelsize'] = 14

    # ðŸ”¹ ComparaciÃ³n de la soluciÃ³n exacta y la aproximada
    fig, ax = plt.subplots()
    plt.plot(xList, uModel(xList), color='b', label="u_approx")
    plt.plot(xList, exactU(xList), color='m', label="u_exact")  
    plt.legend()
    ax.grid(which='both', linestyle=':')
    plt.tight_layout()
    plt.savefig(os.path.join(exp_folder, "comparacion_u.png"), dpi=300)
    plt.close()

    # ðŸ”¹ EvoluciÃ³n de la pÃ©rdida y error relativo
    fig, ax1 = plt.subplots()
    ax1.plot(history.history['loss'], color='g', label="Loss")
    ax1.set_xscale('log')
    ax1.set_yscale('log')
    ax1.set_xlabel("Epoch")
    ax1.set_ylabel("Loss", color='g')

    # ðŸ”¹ Verificar que 'relative_error' existe en history.history antes de graficar
    if 'relative_error' in history.history:
        ax2 = ax1.twinx()
        ax2.plot(history.history['relative_error'], color='b', label="Relative Error")
        ax2.set_ylabel("Relative Error", color='b')

    ax1.grid(which='both', linestyle=':')
    plt.tight_layout()
    plt.savefig(os.path.join(exp_folder, "error_vs_loss.png"), dpi=300)
    plt.close()

    # ðŸ”¹ Error relativo a lo largo de las Ã©pocas
    if 'relative_error' in history.history:
        fig, ax = plt.subplots()
        plt.plot(history.history['relative_error'], color='b', label="Relative Error")
        ax.set_xscale('log')
        plt.legend()
        ax.grid(which='both', linestyle=':')
        plt.tight_layout()
        plt.savefig(os.path.join(exp_folder, "error_relativo.png"), dpi=300)
        plt.close()

def seleccionar_experimentos(resultados):
    """
    Selecciona los experimentos que se van a graficar y los organiza en una lista.

    ParÃ¡metros:
    - resultados (lista): Lista de resultados obtenidos en `ejecutar_entrenamientos`.

    Retorna:
    - todos_experimentos (lista): Lista de experimentos seleccionados para graficar.
    """

    # ðŸ“Œ Determinar la cantidad de lotes segÃºn los experimentos disponibles
    num_lotes = min(len(func), len(resultados)) if len(resultados) > 0 else 1
    lote_size = max(1, len(resultados) // num_lotes) if num_lotes > 0 else 1

    # ðŸ“Œ Lista para almacenar los experimentos seleccionados
    todos_experimentos = []

    for i in range(num_lotes):
        # ðŸ”¹ Seleccionar experimentos de este lote
        lote_resultados = [r for r in resultados if (r[0] - 1) // lote_size == i]
        todos_experimentos.extend(lote_resultados)

    print("âœ” Experimentos listos para generar grÃ¡ficas.")
    return todos_experimentos

def generar_graficas(experimentos, resultados, graficas_path):
    for exp in experimentos:
        exp_id = exp[0]  # ID del experimento
        exp_folder = os.path.join(graficas_path, f"Experimento_{exp_id}")
        os.makedirs(exp_folder, exist_ok=True)

        # Verificar que el resultado tiene 10 elementos
        if len(resultados[exp_id - 1]) < 10:
            print(f"âš  Error: Resultados del experimento {exp_id} tienen solo {len(resultados[exp_id - 1])} elementos.")
            continue  # Saltar este experimento

        try:
            # Acceder a los valores correctos en lugar de hacer slicing [9:]
            uModel = resultados[exp_id - 1][6]
            history = resultados[exp_id - 1][7]
            exactU = resultados[exp_id - 1][8]
            xList = resultados[exp_id - 1][9]

            # Generar grÃ¡ficas
            plot_results(uModel, history, exactU, xList, exp_folder)

        except Exception as e:
            print(f"âš  Error en la generaciÃ³n de grÃ¡ficas para el experimento {exp_id}: {e}")
            continue

    print(f"âœ” Todas las grÃ¡ficas generadas en {graficas_path}.")

def guardar_resultados_excel(resultados_experimentos, funciones_experimentos, carpeta="resultados/PLANTEAMIENTO_2", archivo="resultados.xlsx"):
    """
    Guarda los resultados en un archivo Excel con hojas separadas para cada funciÃ³n de referencia.

    ParÃ¡metros:
    - resultados_experimentos (lista): Lista de resultados de los experimentos.
    - funciones_experimentos (lista): Lista de funciones de referencia utilizadas.
    - carpeta (str): Ruta de la carpeta donde se guardarÃ¡ el archivo Excel.
    - archivo (str): Nombre del archivo Excel.

    Retorna:
    - None
    """
    # ðŸ“Œ Asegurar que la carpeta de destino existe
    os.makedirs(carpeta, exist_ok=True)
    
    # ðŸ“Œ Ruta completa del archivo
    ruta_excel = os.path.join(carpeta, archivo)

    # ðŸ“Œ Definir las columnas que queremos conservar (eliminando 'cpu_percent')
    columnas_base = ["ID", "neurons", "nLayers", "nPts", "error_relativo", "cpu_cost"]

    # ðŸ“Œ Crear un diccionario para agrupar resultados por funciÃ³n de referencia
    resultados_por_funcion = {func["title"]: [] for func in funciones_experimentos}

    # ðŸ“Œ Organizar los resultados en funciÃ³n de la funciÃ³n de referencia utilizada
    num_experimentos_por_funcion = len(resultados_experimentos) // len(funciones_experimentos)

    for i, resultado in enumerate(resultados_experimentos):
        funcion_index = i // num_experimentos_por_funcion
        if funcion_index >= len(funciones_experimentos):
            continue  # Evitar errores si hay mÃ¡s resultados que funciones
        
        titulo_funcion = funciones_experimentos[funcion_index]["title"]

        # ðŸ“Œ Convertir valores a float si son tensores o arrays
        fila_convertida = [
            float(val.numpy()) if isinstance(val, tf.Tensor) else 
            float(val) if isinstance(val, np.ndarray) else val 
            for val in resultado[:6]  
        ]

        resultados_por_funcion[titulo_funcion].append(fila_convertida)

    # ðŸ“Œ Guardar en un archivo Excel con mÃºltiples hojas
    with pd.ExcelWriter(ruta_excel, engine='xlsxwriter') as writer:
        for titulo, datos in resultados_por_funcion.items():
            # ðŸ”¹ Limpiar caracteres no permitidos en nombres de hoja
            titulo_limpio = titulo.replace("*", "x").replace("/", "-").replace("\\", "-").replace("?", "").replace("[", "").replace("]", "").replace(":", "")
            titulo_limpio = titulo_limpio[:31]  # Excel no permite mÃ¡s de 31 caracteres

            df = pd.DataFrame(datos, columns=columnas_base)
            df.to_excel(writer, sheet_name=titulo_limpio, index=False)

    print(f"âœ” Resultados guardados en {ruta_excel} con hojas separadas para cada funciÃ³n de referencia.")

def flujo_experimentos_planteamiento_2():
    """
    Ejecuta el sistema completo de experimentos para el Planteamiento 2, incluyendo:
    - CreaciÃ³n de directorios.
    - EjecuciÃ³n de experimentos con mÃºltiples configuraciones.
    - Almacenamiento de resultados en Excel.
    - GeneraciÃ³n de grÃ¡ficas.
    """
    print("ðŸ“‚ Configurando estructura de almacenamiento...")
    base_path, graficas_path = crear_estructura_directorios()

    print("ðŸš€ Ejecutando experimentos...")
    resultados_experimentos = ejecutar_entrenamientos(func, 9)

    print("ðŸ“Š Seleccionando experimentos para generaciÃ³n de grÃ¡ficas...")
    experimentos_seleccionados = seleccionar_experimentos(resultados_experimentos)

    print("ðŸ“ˆ Generando grÃ¡ficas...")
    generar_graficas(experimentos_seleccionados, resultados_experimentos, graficas_path)

    print("ðŸ’¾ Guardando resultados en archivo Excel...")
    guardar_resultados_excel(resultados_experimentos, funciones_experimentos=funciones_experimentos)

    print("âœ… Proceso finalizado exitosamente.")

flujo_experimentos_planteamiento_2()
