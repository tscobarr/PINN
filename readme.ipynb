{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README: Análisis Comparativo de Planteamientos en Redes Neuronales Informadas por la Física (PINN)\n",
    "\n",
    "## **Introducción**\n",
    "\n",
    "Las ecuaciones diferenciales son fundamentales en la modelación de sistemas físicos, pero su resolución mediante métodos numéricos tradicionales puede ser costosa y compleja. Las Redes Neuronales Informadas por la Física (PINN) han emergido como una alternativa innovadora, integrando el conocimiento físico directamente en el proceso de aprendizaje de la red.\n",
    "\n",
    "Este proyecto compara dos planteamientos distintos para el diseño y entrenamiento de PINNs, con el objetivo de determinar cuál ofrece mejor rendimiento en términos de precisión y eficiencia computacional.\n",
    "\n",
    "## **Marco Teórico**\n",
    "\n",
    "### 1. Redes Neuronales Artificiales\n",
    "Las redes neuronales artificiales (RNA) son modelos computacionales inspirados en la estructura y funcionamiento del cerebro humano. Están compuestas por unidades llamadas neuronas artificiales, organizadas en capas que procesan la información de manera jerárquica. Su entrenamiento se basa en la propagación de información y el ajuste de pesos mediante algoritmos de optimización.\n",
    "\n",
    "### 2. Redes Neuronales Informadas por la Física (PINN)\n",
    "Las PINNs son una variante de redes neuronales diseñadas para resolver ecuaciones diferenciales parciales (PDEs). A diferencia de las redes tradicionales, integran información física en su función de pérdida para garantizar que las soluciones obtenidas cumplan con las ecuaciones diferenciales y sus condiciones de frontera.\n",
    "El entrenamiento de una PINN implica definir una ecuación diferencial como parte de la función de pérdida, evaluar la red en múltiples puntos del dominio y optimizar los parámetros para minimizar el error en la predicción.\n",
    "\n",
    "### 3. Métodos Implementados en PINNs\n",
    "Se han desarrollado dos enfoques principales para la implementación de PINNs:\n",
    "1. **Incorporación Directa de la Ecuación Diferencial**: Se integra la ecuación diferencial y las condiciones de frontera en la función de pérdida. La red neuronal se entrena minimizando esta función.\n",
    "$$\n",
    "\\mathcal{L}(u_{NN}) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( -\\Delta u_{NN}(x_i) + \\alpha u_{NN}(x_i) - f(x_i) \\right)^2\n",
    "$\\lambda_1 \\left( u_{NN}(0) - g(0) \\right)^2 $\n",
    "$\\lambda_2 \\left( u_{NN}(1) - g(1) \\right)^2 $\n",
    "\n",
    "\n",
    "En donde $\\lambda_1$ y $\\lambda_2$ son parámetros.\n",
    "\n",
    "\n",
    "2. **Reformulación de la Solución**: La solución se reformula para satisfacer automáticamente las condiciones de frontera, permitiendo que la red solo aprenda una corrección sobre una solución base.\n",
    "$$\n",
    "u_{NN} = NN(x) \\cdot x \\cdot (x - \\pi)\n",
    "$$\n",
    "\n",
    "Con función de pérdida\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(u_{NN}) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( -\\Delta u_{NN}(x_i) + \\alpha u_{NN}(x_i) - f(x_i) \\right)^2\n",
    "$$\n",
    "\n",
    "3. **Error Relativo**: El error relativo es una métrica que mide la diferencia entre una solución aproximada y la solución exacta en relación con la magnitud de la solución exacta. Se utiliza para evaluar la precisión de modelos numéricos y su desempeño en la aproximación de soluciones a problemas matemáticos.\n",
    "\n",
    "Matemáticamente, el error relativo se define como:\n",
    "\n",
    "$$\n",
    "\\text{Error Relativo} = \\frac{\\|\\text{Solución Exacta} - \\text{Solución Aproximada} \\|}{\\|\\text{Solución Exacta} \\|}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $ \|\text{Solución Exacta} - \text{Solución Aproximada} \| $ representa la diferencia entre ambas soluciones.\n",
    "- $ \|\text{Solución Exacta} \| $ es la norma de la solución exacta utilizada como referencia.\n",
    "\n",
    "El error relativo es útil cuando se comparan soluciones en diferentes escalas, ya que permite evaluar la precisión de una solución aproximada sin verse afectado por el tamaño absoluto de la solución exacta.\n",
    "\n",
    "## **Planteamiento del Problema**\n",
    "Los métodos tradicionales para resolver ecuaciones diferenciales requieren discretización y altos recursos computacionales. Las PINNs han surgido como una alternativa viable, integrando las ecuaciones diferenciales en el proceso de entrenamiento de redes neuronales. Sin embargo, existen múltiples estrategias para implementar las PINNs, y la elección del enfoque adecuado puede impactar significativamente la precisión y eficiencia computacional.\n",
    "\n",
    "En este estudio, se comparan dos metodologías para entrenar PINNs:\n",
    "1. **Incorporación Directa de la Ecuación Diferencial en la Función de Pérdida**.\n",
    "2. **Reformulación de la Solución para Satisfacer Automáticamente las Condiciones de Frontera**.\n",
    "\n",
    "La pregunta clave que este estudio busca responder es:  \n",
    "\n",
    "**¿Cuál de estos dos enfoques proporciona una mejor aproximación en términos de precisión y eficiencia computacional al resolver el siguiente sistema de ecuaciones?**  \n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "-\\Delta u + \\alpha u = f, & x \\in (0,1) \\\\\n",
    "u = g, & x \\in \\{0,1\\}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "## **Objetivos**\n",
    "\n",
    "### Objetivo General\n",
    "Comparar dos planteamientos distintos para entrenar redes neuronales PINN y evaluar su desempeño en la resolución de ecuaciones diferenciales.\n",
    "\n",
    "### Objetivos Específicos\n",
    "- Implementar dos arquitecturas diferentes de PINNs.\n",
    "- Resolver un conjunto de ecuaciones diferenciales mediante cada planteamiento.\n",
    "- Evaluar la precisión de los resultados mediante el error cuadrático medio (L² error).\n",
    "- Analizar el costo computacional de cada enfoque.\n",
    "- Determinar cuál estrategia es más efectiva en términos de precisión y eficiencia computacional.\n",
    "\n",
    "## **Metodología**  \n",
    "\n",
    "**Herramientas y Tecnologías**  \n",
    "Para la implementación de los modelos se utilizaron las siguientes herramientas:  \n",
    "\n",
    "- **Lenguaje de programación**: Python.  \n",
    "- **Bibliotecas**:  \n",
    "  - TensorFlow y Keras para la construcción y entrenamiento de las redes neuronales.  \n",
    "  - Optimizador Adam para el ajuste de pesos.  \n",
    "- **Visualización**: Matplotlib para graficar los resultados y compararlos con la solución analítica.  \n",
    "\n",
    "**Desarrollo e Implementación de Modelos**  \n",
    "Se implementaron dos enfoques distintos para resolver la ecuación diferencial:  \n",
    "\n",
    "- **Planteamiento 1**:  \n",
    "  La ecuación diferencial y las condiciones de frontera se incorporan directamente en la función de pérdida.  \n",
    "\n",
    "- **Planteamiento 2**:  \n",
    "  La solución se reformula para que la red neuronal aprenda solo una corrección sobre una solución base.  \n",
    "\n",
    "**Evaluación del Error**  \n",
    "Se utilizó el **error L²** como métrica principal para evaluar la precisión de los modelos.\n",
    "\n",
    "$$\n",
    "\\text{Error Relativo} =\n",
    "\\frac{\\frac{1}{N} \\sum (u_{NN}(x) - u(x))^2}\n",
    "{\\frac{1}{N} \\sum (u(x))^2}\n",
    "$$\n",
    "\n",
    "\n",
    "**Experimentación y Optimización de Hiperparámetros**  \n",
    "Se realizaron **30 experimentos** con diferentes configuraciones de hiperparámetros para analizar su impacto en la precisión del modelo.  \n",
    "\n",
    "**Comparación y Selección del Mejor Modelo**  \n",
    "Se seleccionó la arquitectura con **mejor precisión** y **menor costo computacional**.  \n",
    "\n",
    "## **Funcionamiento del codigo**\n",
    "\n",
    "\n",
    "### Planteamiento 1\n",
    "\n",
    "#### 1. Configuración Inicial\n",
    "- Se usa **Python** con **TensorFlow/Keras** para construir la red neuronal.\n",
    "- Se establecen **parámetros clave**:\n",
    "  - Número de neuronas y capas en la red.\n",
    "  - Cantidad de puntos de muestreo (`nPts`).\n",
    "  - Iteraciones de entrenamiento (`iterations`).\n",
    "  - Factores de penalización en la función de pérdida (`\\lambda_0, \\lambda_1, \\lambda_2`).\n",
    "\n",
    "#### 2. Construcción del Modelo\n",
    "- `makeModel1(neurons, nLayers, activation)`:  \n",
    "  Crea la red neuronal `uModel1` con capas densas y activación `tanh`.\n",
    "\n",
    "- `Loss1`:  \n",
    "  - Define la **función de pérdida**, incorporando la ecuación diferencial y condiciones de frontera.  \n",
    "  - Usa diferenciación automática (`tf.GradientTape`) para calcular derivadas de `u(x)`.\n",
    "\n",
    "- `makeLossModel1()`:  \n",
    "  - Construye un modelo auxiliar para minimizar la función de pérdida personalizada.\n",
    "\n",
    "#### 3. Entrenamiento del Modelo\n",
    "- Se usa **Adam** como optimizador.\n",
    "- Se define `trickyLoss()` para permitir la optimización de la pérdida `Loss1`.\n",
    "- `RelativeErrorCallback` calcula el error relativo en cada época.\n",
    "- `lossModel1.fit()` entrena la red neuronal durante `500` iteraciones.\n",
    "\n",
    "#### 4. Evaluación y Visualización\n",
    "- `plotResults()`:  \n",
    "  - Grafica la solución aproximada vs. la solución exacta.\n",
    "  - Muestra la evolución de la pérdida (`loss`) y el error relativo (`relative error`).\n",
    "\n",
    "#### 5. Ejecución Final\n",
    "- Se entrena la red neuronal y se evalúa el desempeño comparando con la solución exacta.\n",
    "\n",
    "### Planteamiento 2\n",
    "\n",
    "\n",
    "\n",
    "#### 1. Configuración Inicial\n",
    "- Se usa **Python** con **TensorFlow/Keras** para construir la red neuronal.  \n",
    "- Se establecen **parámetros clave**:\n",
    "  - Número de neuronas y capas en la red.\n",
    "  - Cantidad de puntos de muestreo (`nPts`).\n",
    "  - Iteraciones de entrenamiento (`iterations`).\n",
    "\n",
    "#### 2. Construcción del Modelo\n",
    "- `makeModel2(neurons, nLayers, activation)`:  \n",
    "  - Se genera una red neuronal con capas densas y activación `tanh`.  \n",
    "  - Se **garantiza que la solución cumple automáticamente las condiciones de frontera** multiplicando la salida por una función de contorno:  \n",
    "    $$\n",
    "    u_{NN}(x) = NN(x) \\cdot (x - x_{\\text{min}}) \\cdot (x - x_{\\text{max}})\n",
    "    $$\n",
    "\n",
    "- `Loss2`:  \n",
    "  - Define la **función de pérdida**, incorporando la ecuación diferencial.  \n",
    "  - Usa diferenciación automática (`tf.GradientTape`) para calcular derivadas de `u(x)`.  \n",
    "  - **No se incluyen términos de penalización de frontera**, ya que la solución reformulada las satisface por construcción.  \n",
    "\n",
    "- `makeLossModel2()`:  \n",
    "  - Construye un modelo auxiliar para minimizar la función de pérdida personalizada.  \n",
    "\n",
    "#### 3. Entrenamiento del Modelo\n",
    "- Se usa **Adam** como optimizador.  \n",
    "- Se define `trickyLoss()` para permitir la optimización de la pérdida `Loss2`.  \n",
    "- `RelativeErrorCallback` calcula el error relativo en cada época.  \n",
    "- `lossModel2.fit()` entrena la red neuronal durante `500` iteraciones.  \n",
    "\n",
    "#### 4. Evaluación y Visualización\n",
    "- `plotResults()`:  \n",
    "  - Grafica la solución aproximada vs. la solución exacta.  \n",
    "  - Muestra la evolución de la pérdida (`loss`) y el error relativo (`relative error`).  \n",
    "\n",
    "#### 5. Ejecución Final\n",
    "- Se entrena la red neuronal y se evalúa el desempeño comparando con la solución exacta.  \n",
    "\n",
    "\n",
    "**Nota**: **tricky loss** en ambos casos es simplemente **return yTrue**, lo que significa que la optimización no se realiza directamente sobre la pérdida calculada en la ecuación diferencial. Esto permite el uso de otro **modelo auxiliar** que corrige el error del primerO.\n",
    "\n",
    "## Conclusiones y Trabajo Futuro\n",
    "(Se deben agregar las conclusiones y las posibles direcciones futuras de la investigación).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
